{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosillanaldariz/miniconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.6366 - loss: 0.9283 - val_accuracy: 0.6558 - val_loss: 0.8783\n",
      "Epoch 2/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.6378 - loss: 0.9120 - val_accuracy: 0.6558 - val_loss: 0.8814\n",
      "Epoch 3/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.6447 - loss: 0.9066 - val_accuracy: 0.6558 - val_loss: 0.8724\n",
      "Epoch 4/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.6557 - loss: 0.8727 - val_accuracy: 0.6558 - val_loss: 0.8752\n",
      "Epoch 5/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 51ms/step - accuracy: 0.6514 - loss: 0.8717 - val_accuracy: 0.6558 - val_loss: 0.8656\n",
      "Epoch 6/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.6479 - loss: 0.8744 - val_accuracy: 0.6558 - val_loss: 0.8715\n",
      "Epoch 7/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.6585 - loss: 0.8614 - val_accuracy: 0.6558 - val_loss: 0.8685\n",
      "Epoch 8/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.6478 - loss: 0.8743 - val_accuracy: 0.6558 - val_loss: 0.8703\n",
      "Epoch 9/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.6520 - loss: 0.8681 - val_accuracy: 0.6558 - val_loss: 0.8715\n",
      "Epoch 10/10\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.6371 - loss: 0.8811 - val_accuracy: 0.6558 - val_loss: 0.8676\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.00      0.00      0.00       347\n",
      "     Bullish       0.00      0.00      0.00       475\n",
      "     Neutral       0.66      1.00      0.79      1566\n",
      "\n",
      "    accuracy                           0.66      2388\n",
      "   macro avg       0.22      0.33      0.26      2388\n",
      "weighted avg       0.43      0.66      0.52      2388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosillanaldariz/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/carlosillanaldariz/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/carlosillanaldariz/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Cargar los datos\n",
    "def load_data(train_path, valid_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    valid_df = pd.read_csv(valid_path)\n",
    "    return train_df, valid_df\n",
    "\n",
    "train_path = \"sent_train.csv\"\n",
    "valid_path = \"sent_valid.csv\"\n",
    "train_df, valid_df = load_data(train_path, valid_path)\n",
    "\n",
    "# 2. Preprocesamiento de texto\n",
    "MAX_NUM_WORDS = 10000  # Máximo número de palabras en el vocabulario\n",
    "MAX_SEQUENCE_LENGTH = 50  # Longitud máxima de las secuencias\n",
    "EMBEDDING_DIM = 100  # Dimensión de las incrustaciones de palabras\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df[\"text\"])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_df[\"text\"])\n",
    "X_valid = tokenizer.texts_to_sequences(valid_df[\"text\"])\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
    "X_valid = pad_sequences(X_valid, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "y_train = to_categorical(train_df[\"label\"], num_classes=3)\n",
    "y_valid = to_categorical(valid_df[\"label\"], num_classes=3)\n",
    "\n",
    "# 3. Definir el modelo LSTM\n",
    "def build_lstm_model():\n",
    "    model = Sequential([\n",
    "        Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(3, activation='softmax')  # 3 clases de salida\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_lstm_model()\n",
    "\n",
    "# 4. Entrenar el modelo\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 5. Evaluar el modelo\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_valid, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, target_names=[\"Bearish\", \"Bullish\", \"Neutral\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
